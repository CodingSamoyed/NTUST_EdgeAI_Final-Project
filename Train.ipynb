{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the training code is based on the work of Jason Wong, the link to the original code is listed as below：\n",
    "https://www.kaggle.com/code/jasonhcwong/dog-breed-classification-using-efficientnet/notebook  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B0\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the below code if using Google Colab for training, and the training dataset is in Google Drive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將Google Drive掛載到Colab\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size_per_replica = 128\n",
    "batch_size_global = 256\n",
    "# reserve 20% of the images in dataset for evaluation\n",
    "testsplit = .2\n",
    "# targetx and targety should be set to the input size of the classification network\n",
    "targetx = 224\n",
    "targety = 224\n",
    "learning_rate = 0.0001\n",
    "classes = 8                # Modify it accroding the classes you are preparing to train\n",
    "seed = 777\n",
    "\n",
    "#Change and create the file directory based on your situation\n",
    "data_dir = \"/content/drive/MyDrive/Stanford_Dogs/Images/\"\n",
    "annotations_dir = \"/content/drive/MyDrive/Stanford_Dogs/Annotations/\"\n",
    "cropped_dir = \"/content/drive/MyDrive/Stanford_Dogs/Cropped/\"\n",
    "checkpoint_path = \"/content/drive/MyDrive/Stanford_Dogs/Checkpoints/\"\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "  tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "# create a mirrored strategy so that we can utilise multiple GPUs\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(mirrored_strategy.num_replicas_in_sync))\n",
    "\n",
    "# adjust global batch size according the number of GPUS detected\n",
    "batch_size_global = (batch_size_per_replica * mirrored_strategy.num_replicas_in_sync)\n",
    "print('Global batch size: {}'.format(batch_size_global))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare images for training\n",
    "\n",
    "Note：\n",
    "\n",
    "    － Stanford Dogs Dataset contains large images of dogs, class labels and bounding boxes. In order to achieve a better result, the bounding boxes are used to crop the close-up of dogs in the images. The cropped close-up images will then be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%system rm -rf $cropped_dir\n",
    "%system mkdir $cropped_dir\n",
    "\n",
    "#this function adapted from https://www.kaggle.com/hengzheng/dog-breeds-classifier\n",
    "def save_cropped_img(path, annotation, newpath):\n",
    "    tree = ET.parse(annotation+\".xml\")                      # Change the +\".type\" accrding to your annotation file name and format\n",
    "    # tree = ET.parse(annotation)                           # Enable this if your dataset is from Stanford Dogs only\n",
    "    xmin = int(tree.getroot().findall('.//xmin')[0].text)\n",
    "    xmax = int(tree.getroot().findall('.//xmax')[0].text)\n",
    "    ymin = int(tree.getroot().findall('.//ymin')[0].text)\n",
    "    ymax = int(tree.getroot().findall('.//ymax')[0].text)\n",
    "    image = Image.open(path)\n",
    "    image = image.crop((xmin, ymin, xmax, ymax))\n",
    "    image = image.convert('RGB')\n",
    "    image.save(newpath)\n",
    "\n",
    "def crop_images():\n",
    "    breeds = os.listdir(data_dir)\n",
    "    annotations = os.listdir(annotations_dir)\n",
    "\n",
    "    print('breeds: ', len(breeds), 'annotations: ', len(annotations))\n",
    "\n",
    "    total_images = 0\n",
    "\n",
    "    for breed in breeds:\n",
    "        dir_list = os.listdir(data_dir + breed)\n",
    "        annotations_dir_list = os.listdir(annotations_dir + breed)\n",
    "        img_list = [data_dir + breed + '/' + i for i in dir_list]\n",
    "        os.makedirs(cropped_dir + breed)\n",
    "\n",
    "        for file in img_list:\n",
    "            annotation_path = annotations_dir + breed + '/' + os.path.basename(file[:-4])\n",
    "            newpath = cropped_dir + breed + '/' + os.path.basename(file)\n",
    "            save_cropped_img(file, annotation_path, newpath)\n",
    "            total_images += 1\n",
    "    \n",
    "    print(\"total images cropped\", total_images)\n",
    "\n",
    "crop_images()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset for training and evaluation\n",
    "\n",
    "Note：\n",
    "\n",
    "    －A tf.data.Dataset is created from the image files in the directory created in the previous step.\n",
    "    －The dataset splited into a training set of 80% images and a evaluation set of 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset = tf.keras.utils.image_dataset_from_directory(\n",
    "    cropped_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size_global,\n",
    "    image_size=(targetx, targety),\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    "    validation_split=testsplit,\n",
    "    subset='both',\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")\n",
    "\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO\n",
    "trainset = trainset.with_options(options).prefetch(tf.data.AUTOTUNE)\n",
    "valset = valset.with_options(options)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Keras callbacks for training\n",
    "\n",
    "Note：\n",
    "\n",
    "    －Callbacks that can provides useful information and fine tuning during model training.\n",
    "        －ModelCheckpoint callback: it saves a model at a speicified frequency\n",
    "        －TensorBoard callback: it saves logs which enable visualization for TensorBoard for inspection after the training.\n",
    "        －EarlyStopping callback: it stopes the training when a monitored metric(evaluation accurary in this case) has stopped improving\n",
    "        －ReduceLROnPlateau callback: it decrease the learning rate when a metric(evaluation accurary in this case) has stopped improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_accuracy',\n",
    "                             save_best_only=False,\n",
    "                             verbose=1,\n",
    "                             mode='auto',\n",
    "                             save_weights_only=False,\n",
    "                             save_freq='epoch')\n",
    "\n",
    "#https://github.com/keras-team/keras/issues/3358\n",
    "tensorboard = TensorBoard(log_dir=\"./logs\",\n",
    "                            histogram_freq=0,\n",
    "                            batch_size=batch_size_global,\n",
    "                            write_graph=False,\n",
    "                            update_freq='epoch')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_accuracy',\n",
    "                          min_delta=.0001,\n",
    "                          patience=10,\n",
    "                          verbose=1,\n",
    "                          mode='auto',\n",
    "                          baseline=None,\n",
    "                          restore_best_weights=True)\n",
    "\n",
    "reducelr = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                             factor=np.sqrt(.1),\n",
    "                             patience=5,\n",
    "                             verbose=1,\n",
    "                             mode='auto',\n",
    "                             min_delta=.0001,\n",
    "                             cooldown=0,\n",
    "                             min_lr=0.0000001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model\n",
    "\n",
    "Note：\n",
    "\n",
    "    － A pre-trained model EfficientNetV2B0 from Keras library is used for transfer learning, We copy the network weights except the top layers from the pre-trained model.\n",
    "    - The model can be trained much faster by using transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    base_model = EfficientNetV2B0(include_top=False, weights='imagenet', input_shape=(targetx, targety, 3))\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(1280, activation='relu', bias_initializer='zeros')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    predictions = Dense(classes, activation='softmax', kernel_initializer='random_uniform', bias_initializer='zeros')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "    loss = \"categorical_crossentropy\"\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss=loss,\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "#model.summary()\n",
    "#for i, layer in enumerate(model.layers):\n",
    "#    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = model.fit(trainset, \n",
    "                    validation_data=valset,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[reducelr, earlystop, tensorboard, checkpoint])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model as TensorFlow SavedModel format\n",
    "model.save('/content/drive/MyDrive/Stanford_Dogs/Model/')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert saved Keras model into TensorFlowLite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = tf.keras.models.load_model('/content/drive/MyDrive/Stanford_Dogs/Model/')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "converter.experimental_new_converter = True\n",
    "tflite_model = converter.convert()\n",
    "# open('converted_model.tflite', 'wb').write(tflite_model)\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
